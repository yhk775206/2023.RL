{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3G5iboOTlxvPFruBRdvo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yhk775206/2023.RL/blob/main/a_karmed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Toy k-armed *bandit*"
      ],
      "metadata": {
        "id": "9lfpvgvtMB3W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ml6m0N5tCNnq"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 초기화\n",
        "# (1) bandit 설정 (bandit 1 ~ 3을 사용할 것이므로 bandit[0]은 0으로 초기화)\n",
        "# 0번 bandit은 쓰지 않음\n",
        "bandit = [[0, 0, 0, 0, 0],\n",
        "          [1, 0, 8, 5, 2],\n",
        "          [0, 1, -1, 2, 28],\n",
        "          [7, -3, -3, -3, -3]]\n",
        "\n",
        "# (2) bandit에서 실행할 횟수\n",
        "action = [0, -1, -1, -1]\n",
        "\n",
        "# (3) Q 함수 (0으로 초기화)\n",
        "Q = np.array([-1.0, 0.0, 0.0, 0.0])\n",
        "\n",
        "# (4) alpha를 0.5로 초기화\n",
        "alpha = 0.5"
      ],
      "metadata": {
        "id": "_54ETy3qCYEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. k-armed bandit 수행\n",
        "# (1) 1번째로 선택할 bandit의 action을 선택\n",
        "selected = 3\n",
        "print(f\"[1] bandit {selected}\")\n",
        "action[selected] +=1\n",
        "\n",
        "# (2) 2~5번째(4번) bandit 선택을 수행\n",
        "for i in range(1, 5):\n",
        "    # (2-1) 선택한 bandit의 reward 가져오기\n",
        "    reward = bandit[selected][action[selected]]\n",
        "\n",
        "    # (2-2) 선택된 bandit의 Q 값 갱신: Q = Q + alpha * (R - Q)\n",
        "    Q[selected] = Q[selected] + alpha * (reward - Q[selected])\n",
        "\n",
        "    # (2-3) 다음 action 선택\n",
        "    selected = np.argmax(Q)\n",
        "    print(f\"[{i+1}]-th bandit {selected} is selected\")\n",
        "\n",
        "    # (2-4) 선택한 bandit의 다음 action으로 이동\n",
        "    action[selected] += 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XygzpHRHDtJ0",
        "outputId": "0f404cc3-d7b9-424b-f091-72da5333a02a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] bandit 3\n",
            "[2]-th bandit 3 is selected\n",
            "[3]-th bandit 3 is selected\n",
            "[4]-th bandit 1 is selected\n",
            "[5]-th bandit 1 is selected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Sample-average method\n",
        "#### 1) Bandit class 정의"
      ],
      "metadata": {
        "id": "T6G-Wmg0MHlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Bandit class 정의\n",
        "class Bandit:\n",
        "    # (1) 변수 설정\n",
        "    def __init__(self, k, means, std_devs):\n",
        "        self.k = k\n",
        "        self.rewards = np.array([np.random.normal(loc=mean, scale=std_dev)\n",
        "                                          for mean, std_dev in zip(means, std_devs)])\n",
        "        self.Qs = np.zeros(k) # action values for each action\n",
        "        self.num_selected = np.zeros(k) # number of times each action was selected\n",
        "\n",
        "    # (2) reward 함수 정의: 선택한 action에 대한 reward를 return\n",
        "    def get_reward(self, action):\n",
        "        reward = self.rewards[action]\n",
        "        return reward\n",
        "\n",
        "    # (3) action 선택 함수 정의: 다음 action은 action_values (Qs) 중에서\n",
        "    #     가장 큰 값으로 선택\n",
        "    def choose_action(self):\n",
        "        action = np.argmax(self.Qs)\n",
        "        return action\n",
        "\n",
        "    # (4) action value (Q)를 update하는 함수 정의\n",
        "    def update_Qs(self, action, reward):\n",
        "        self.num_selected[action] += 1\n",
        "        alpha = 1.0 / self.num_selected[action]\n",
        "        self.Qs[action] += alpha * (reward - self.Qs[action])\n"
      ],
      "metadata": {
        "id": "CuZlSjVUMSp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) 초기화"
      ],
      "metadata": {
        "id": "4hoJbqLUMpPV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 초기화\n",
        "# (1) arm의 수 설정\n",
        "k = 3\n",
        "\n",
        "# (2) k-armed baidnt 초기화: Mean values for each action\n",
        "# means, std_devs -> bandit 선언\n",
        "means = [2.75, 2.0, 2.5]\n",
        "std_devs = [0.5, 3.0, 2.0]\n",
        "bandit = Bandit(k, means, std_devs)\n",
        "\n",
        "# (3) 수행 횟수 설정\n",
        "n_iterations = 1000"
      ],
      "metadata": {
        "id": "HhrMvgPdMreU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) k-armed bandit 실행"
      ],
      "metadata": {
        "id": "XzltA6CxMsAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. k-armed bandit 실행\n",
        "sum_reward = 0\n",
        "for i in range(n_iterations):\n",
        "    # (1) action을 수행할 bandit을  결정\n",
        "    action = bandit.choose_action()\n",
        "    # 첫번째 action은 1로 선택\n",
        "    if (i == 0):\n",
        "        action = 1\n",
        "        print(action)\n",
        "\n",
        "    # (2) 선택한 action의 reward 가져오기\n",
        "    reward = bandit.get_reward(action)\n",
        "    sum_reward += reward\n",
        "\n",
        "    # (3) 선택한 action의 Q 값 갱신\n",
        "    bandit.update_Qs(action, reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WOc_PdOoMvo8",
        "outputId": "039f05f7-2bdb-4940-f093-31353c65b5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of selections for each action: \", bandit.num_selected)\n",
        "print(\"Estimated values for each action: \", bandit.Qs)\n",
        "print(\"Sum of reward:\", sum_reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WL3FVmZyQUc6",
        "outputId": "c8de6bbd-13e8-4725-fc03-8730b3cbd199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of selections for each action:  [   0. 1000.    0.]\n",
            "Estimated values for each action:  [0.         2.03796579 0.        ]\n",
            "Sum of reward: 2037.9657911784761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. epsilon-greedy method"
      ],
      "metadata": {
        "id": "Rj0JeQU1SIei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Bandit class 정의\n",
        "class Bandit:\n",
        "    # (1) 변수 설정\n",
        "    def __init__(self, k, means, std_devs):\n",
        "        self.k = k\n",
        "        self.rewards = np.array([np.random.normal(loc=mean, scale=std_dev)\n",
        "                                          for mean, std_dev in zip(means, std_devs)])\n",
        "        self.Qs = np.zeros(k) # action values for each action\n",
        "        self.num_selected = np.zeros(k) # number of times each action was selected\n",
        "        self.epsilon = 0.1\n",
        "\n",
        "    # (2) reward 함수 정의: 선택한 action에 대한 reward를 return\n",
        "    def get_reward(self, action):\n",
        "        reward = self.rewards[action]\n",
        "        return reward\n",
        "\n",
        "    # (3) random number를 선택\n",
        "    #     이 값이 epsilon보다 작으면 random한 bandit 선택\n",
        "    #     이 값이 epsilon보다 크면 이전과 같음\n",
        "    def choose_action(self):\n",
        "        if np.random.random() < self.epsilon:\n",
        "            action = np.random.choice(self.k)\n",
        "        else:\n",
        "            action = np.argmax(self.Qs)\n",
        "        return action\n",
        "\n",
        "    # (4) action value (Q)를 update하는 함수 정의\n",
        "    def update_Qs(self, action, reward):\n",
        "        self.num_selected[action] += 1\n",
        "        alpha = 1.0 / self.num_selected[action]\n",
        "        self.Qs[action] += alpha * (reward - self.Qs[action])\n",
        "\n",
        "# 2. 초기화\n",
        "# (1) arm의 수 설정\n",
        "k = 3\n",
        "\n",
        "# (2) k-armed baidnt 초기화: Mean values for each action\n",
        "# means, std_devs -> bandit 선언\n",
        "means = [2.75, 2.0, 2.5]\n",
        "std_devs = [0.5, 3.0, 2.0]\n",
        "bandit = Bandit(k, means, std_devs)\n",
        "\n",
        "# (3) 수행 횟수 설정\n",
        "n_iterations = 1000\n",
        "\n",
        "# 3. k-armed bandit 실행\n",
        "sum_reward = 0\n",
        "for i in range(n_iterations):\n",
        "    # (1) action을 수행할 bandit을  결정\n",
        "    action = bandit.choose_action()\n",
        "    # 첫번째 action은 1로 선택\n",
        "    if (i == 0):\n",
        "        action = 1\n",
        "        print(action)\n",
        "\n",
        "    # (2) 선택한 action의 reward 가져오기\n",
        "    reward = bandit.get_reward(action)\n",
        "    sum_reward += reward\n",
        "\n",
        "    # (3) 선택한 action의 Q 값 갱신\n",
        "    bandit.update_Qs(action, reward)\n",
        "\n",
        "print(\"Number of selections for each action: \", bandit.num_selected)\n",
        "print(\"Estimated values for each action: \", bandit.Qs)\n",
        "print(\"Sum of reward:\", sum_reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxaJFTjcSSYH",
        "outputId": "72943721-d518-4940-a2d2-286bd72044b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Number of selections for each action:  [ 75.  34. 891.]\n",
            "Estimated values for each action:  [ 3.17583278 -1.83699854  4.30424481]\n",
            "Sum of reward: 4010.811629336359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Optimistic initial value"
      ],
      "metadata": {
        "id": "DQjbf_-8TuN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Bandit class 정의\n",
        "class Bandit:\n",
        "    # (1) 변수 설정\n",
        "    def __init__(self, k, means, std_devs, initial_value):\n",
        "        self.k = k\n",
        "        self.rewards = np.array([np.random.normal(loc=mean, scale=std_dev)\n",
        "                                          for mean, std_dev in zip(means, std_devs)])\n",
        "        #self.Qs = np.zeros(k) # action values for each action\n",
        "        self.Qs = np.full(k, initial_value)  # action values for each action\n",
        "        self.num_selected = np.zeros(k) # number of times each action was selected\n",
        "\n",
        "    # (2) reward 함수 정의: 선택한 action에 대한 reward를 return\n",
        "    def get_reward(self, action):\n",
        "        reward = self.rewards[action]\n",
        "        return reward\n",
        "\n",
        "    # (3) random number를 선택\n",
        "    #     이 값이 epsilon보다 작으면 random한 bandit 선택\n",
        "    #     이 값이 epsilon보다 크면 이전과 같음\n",
        "    def choose_action(self):\n",
        "        action = np.argmax(self.Qs)\n",
        "        return action\n",
        "\n",
        "    # (4) action value (Q)를 update하는 함수 정의\n",
        "    def update_Qs(self, action, reward):\n",
        "        self.num_selected[action] += 1\n",
        "        alpha = 1.0 / self.num_selected[action]\n",
        "        self.Qs[action] += alpha * (reward - self.Qs[action])\n",
        "\n",
        "# 2. 초기화\n",
        "# (1) arm의 수 설정\n",
        "k = 3\n",
        "\n",
        "# (2) k-armed baidnt 초기화: Mean values for each action\n",
        "# means, std_devs -> bandit 선언\n",
        "means = [2.75, 2.0, 2.5]\n",
        "std_devs = [0.5, 3.0, 2.0]\n",
        "initial_value = 10.0\n",
        "bandit = Bandit(k, means, std_devs, initial_value)\n",
        "\n",
        "# (3) 수행 횟수 설정\n",
        "n_iterations = 1000\n",
        "\n",
        "# 3. k-armed bandit 실행\n",
        "sum_reward = 0\n",
        "for i in range(n_iterations):\n",
        "    # (1) action을 수행할 bandit을  결정\n",
        "    action = bandit.choose_action()\n",
        "    # 첫번째 action은 1로 선택\n",
        "    if (i == 0):\n",
        "        action = 1\n",
        "        print(action)\n",
        "\n",
        "    # (2) 선택한 action의 reward 가져오기\n",
        "    reward = bandit.get_reward(action)\n",
        "    sum_reward += reward\n",
        "\n",
        "    # (3) 선택한 action의 Q 값 갱신\n",
        "    bandit.update_Qs(action, reward)\n",
        "\n",
        "print(\"Number of selections for each action: \", bandit.num_selected)\n",
        "print(\"Estimated values for each action: \", bandit.Qs)\n",
        "print(\"Sum of reward:\", sum_reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1KfT8YMTw_t",
        "outputId": "9edb56be-f7e8-439d-e016-7f3b9340a2f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Number of selections for each action:  [  1.   1. 998.]\n",
            "Estimated values for each action:  [2.42336684 2.91849719 6.28727816]\n",
            "Sum of reward: 6280.045470880532\n"
          ]
        }
      ]
    }
  ]
}